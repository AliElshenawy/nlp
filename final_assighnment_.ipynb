{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_assighnment .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pp2l-lRHiLe4",
        "RoJ3S81riRD0",
        "X62GZ5ruiVp2",
        "QAcCgRwMyvkA",
        "5LE2XaO-4jFo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Student Name: Ali Mahmode Ali Elsayed \n",
        "# ID:300327244\n",
        "# email: aelsh053@uottawa.ca"
      ],
      "metadata": {
        "id": "ipSb8YmWoIEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# three wayes for that task \n",
        "\n",
        "1- using url\n",
        "\n",
        "2- using local_file\n",
        "\n",
        "3- using the name from ntlk library "
      ],
      "metadata": {
        "id": "EkQ8cO6QhytX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import libraries"
      ],
      "metadata": {
        "id": "pp2l-lRHiLe4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVzhGC6ecWZG",
        "outputId": "e40e1076-eb6d-4c55-e2f7-539974d41557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (1.27.12)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import re \n",
        "import requests\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords,gutenberg\n",
        "import random\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split_text_using url"
      ],
      "metadata": {
        "id": "RoJ3S81riRD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_using_url(url,label_book,no_split=200,num_word=100): \n",
        "  final_list_books=[]\n",
        "  final_list_paragraph=[]\n",
        "  final_list_label=[]\n",
        "  for index in range(len(url)):\n",
        "\n",
        "#read book and make it lower \n",
        "     book = requests.get(url[index])\n",
        "     book.encoding='utf-8-sig' #to prevent the problem of ascii code\n",
        "     data_book = book.text.lower()# because when remove stopworks not remove \"The\" or upper letter if found \n",
        "     data_book\n",
        "  \n",
        "#split the text into words \n",
        "     all_list=re.findall(r'\\w+', data_book)\n",
        "     #print(all_list)\n",
        "  \n",
        "#remove the special cases \n",
        "     clean_list1=[]\n",
        "     for i in all_list:\n",
        "        if re.match(\"[a-zA-Z]+\",i):\n",
        "          clean_list1.append(i)\n",
        "     #print(len(all_list))\n",
        "     #print(len(clean_list1))\n",
        "     #print(clean_list1)\n",
        "\n",
        "#remove stopwords\n",
        "     stopwords = nltk.corpus.stopwords.words('english')\n",
        "     clean_list2=[]\n",
        "     for i in clean_list1:\n",
        "        if i not in stopwords:\n",
        "          clean_list2.append(i)\n",
        "     #print(len(clean_list1))\n",
        "     #print(len(clean_list2))\n",
        "     #print(clean_list2)\n",
        "  \n",
        "#split data_text to 200 sample and each of it contain 100 words\n",
        "     list=[]\n",
        "     list_label=[]\n",
        "     for i in range(200):\n",
        "       random_num=random.randint(0,100)\n",
        "       #list.append(clean_list2[i*100:i*100+100]) #that not random \n",
        "       list.append(clean_list2[random_num*100:random_num*100+100])#that random\n",
        "       list_label.append(label_book[index])\n",
        "     final_list_books=final_list_books+list  \n",
        "     final_list_label=final_list_label+list_label\n",
        "     #print(list)   \n",
        "  \n",
        "#prepare paragraph from list\n",
        "     paragraph=\" \"\n",
        "     paragraph_list=[]\n",
        "     for x in list:\n",
        "         paragraph=paragraph.join(x) \n",
        "         paragraph_list.append(paragraph)\n",
        "         paragraph=\" \"\n",
        "     final_list_paragraph =final_list_paragraph + paragraph_list \n",
        "#show lists with each label \n",
        "     df=pd.DataFrame({\"part\":final_list_books,\"paragraph\":final_list_paragraph,\"book\":final_list_label})\n",
        "    #  df['paragraph']=paragraph_list\n",
        "    #  df['part']=list\n",
        "    #  df['book']=list_label\n",
        "  return df"
      ],
      "metadata": {
        "id": "7Cs-qS3ScYFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#call function"
      ],
      "metadata": {
        "id": "X62GZ5ruiVp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=split_text_using_url([\"https://www.gutenberg.org/cache/epub/68061/pg68061.txt\",\"https://www.gutenberg.org/cache/epub/68061/pg68061.txt\"],['b','a'],200,100)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ciLJIkrRgwkb",
        "outputId": "9123c944-d6aa-4820-ee1f-b69f4d2e890f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  part  \\\n",
              "0    [importance, country, mainly, due, dawl, thank...   \n",
              "1    [days, giving, supper, parties, friends, nobod...   \n",
              "2    [cried, master, nathaniel, violently, endymion...   \n",
              "3    [agents, smuggled, town, eat, fairy, fruit, re...   \n",
              "4    [old, working, woman, unfeigned, interest, sho...   \n",
              "..                                                 ...   \n",
              "395  [stamping, feet, banging, table, whereupon, ma...   \n",
              "396  [old, working, woman, unfeigned, interest, sho...   \n",
              "397  [beginning, little, anxious, ranulph, hempie, ...   \n",
              "398  [strings, rotted, damp, antiquity, crying, let...   \n",
              "399  [attitude, exquisite, pleasure, would, say, pl...   \n",
              "\n",
              "                                             paragraph book  \n",
              "0    importance country mainly due dawl thanks dawl...    b  \n",
              "1    days giving supper parties friends nobody lud ...    b  \n",
              "2    cried master nathaniel violently endymion leer...    b  \n",
              "3    agents smuggled town eat fairy fruit regarded ...    b  \n",
              "4    old working woman unfeigned interest showed co...    b  \n",
              "..                                                 ...  ...  \n",
              "395  stamping feet banging table whereupon master n...    a  \n",
              "396  old working woman unfeigned interest showed co...    a  \n",
              "397  beginning little anxious ranulph hempie shot s...    a  \n",
              "398  strings rotted damp antiquity crying let see o...    a  \n",
              "399  attitude exquisite pleasure would say pleasant...    a  \n",
              "\n",
              "[400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31741ce9-e9e8-475d-b068-0cb1a734686b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>part</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>book</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[importance, country, mainly, due, dawl, thank...</td>\n",
              "      <td>importance country mainly due dawl thanks dawl...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[days, giving, supper, parties, friends, nobod...</td>\n",
              "      <td>days giving supper parties friends nobody lud ...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[cried, master, nathaniel, violently, endymion...</td>\n",
              "      <td>cried master nathaniel violently endymion leer...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[agents, smuggled, town, eat, fairy, fruit, re...</td>\n",
              "      <td>agents smuggled town eat fairy fruit regarded ...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[old, working, woman, unfeigned, interest, sho...</td>\n",
              "      <td>old working woman unfeigned interest showed co...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>[stamping, feet, banging, table, whereupon, ma...</td>\n",
              "      <td>stamping feet banging table whereupon master n...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>[old, working, woman, unfeigned, interest, sho...</td>\n",
              "      <td>old working woman unfeigned interest showed co...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>[beginning, little, anxious, ranulph, hempie, ...</td>\n",
              "      <td>beginning little anxious ranulph hempie shot s...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>[strings, rotted, damp, antiquity, crying, let...</td>\n",
              "      <td>strings rotted damp antiquity crying let see o...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>[attitude, exquisite, pleasure, would, say, pl...</td>\n",
              "      <td>attitude exquisite pleasure would say pleasant...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31741ce9-e9e8-475d-b068-0cb1a734686b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31741ce9-e9e8-475d-b068-0cb1a734686b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31741ce9-e9e8-475d-b068-0cb1a734686b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split_text_using name\n",
        "\n",
        "1- that will make error as files were local , but i wanted to make it generalized "
      ],
      "metadata": {
        "id": "QAcCgRwMyvkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_using_name(name_books,label_book,no_split=200,num_word=100):\n",
        "  final_list_books=[]\n",
        "  final_list_paragraph=[]\n",
        "  final_list_label=[]\n",
        "  for index in range(len(name_books)):\n",
        "\n",
        "  #read book and make it lower \n",
        "   \n",
        "     with open(name_books[index]) as f: \n",
        "      lines = f.read()\n",
        "      data_book=lines.lower()\n",
        "     #print(lines.lower())     \n",
        "\n",
        "  \n",
        "   #split the text into words \n",
        "     all_list=re.findall(r'\\w+', data_book)\n",
        "   #print(all_list)\n",
        "  \n",
        "  #remove the special cases \n",
        "     clean_list1=[]\n",
        "     for i in all_list:\n",
        "        if re.match(\"[a-zA-Z]+\",i):\n",
        "          clean_list1.append(i)\n",
        "     #print(len(all_list))\n",
        "     #print(len(clean_list1))\n",
        "     #print(clean_list1)\n",
        "\n",
        "  #remove stopwords\n",
        "     stopwords = nltk.corpus.stopwords.words('english')\n",
        "     clean_list2=[]\n",
        "     for i in clean_list1:\n",
        "        if i not in stopwords:\n",
        "          clean_list2.append(i)\n",
        "     #print(len(clean_list1))\n",
        "     #print(len(clean_list2))\n",
        "     #print(clean_list2)\n",
        "  \n",
        "  #split data_text to 200 sample and each of it contain 100 words\n",
        "     list=[]\n",
        "     list_label=[]\n",
        "     for i in range(200):\n",
        "       list.append(clean_list2[i*100:i*100+100])\n",
        "       list_label.append(label_book[index])\n",
        "     final_list_books=final_list_books+list  \n",
        "     final_list_label=final_list_label+list_label\n",
        "  #print(list)   \n",
        "#prepare paragraph from list\n",
        "     paragraph=\" \"\n",
        "     paragraph_list=[]\n",
        "     for x in list:\n",
        "         paragraph=paragraph.join(x) \n",
        "         paragraph_list.append(paragraph)\n",
        "         paragraph=\" \"\n",
        "     final_list_paragraph =final_list_paragraph + paragraph_list \n",
        "#show lists with each label \n",
        "     df=pd.DataFrame({\"part\":final_list_books,\"paragraph\":final_list_paragraph,\"book\":final_list_label})\n",
        "    #  df['paragraph']=paragraph_list\n",
        "    #  df['part']=list\n",
        "    #  df['book']=list_label\n",
        "  return df"
      ],
      "metadata": {
        "id": "UtxoFyF3ysCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#call function "
      ],
      "metadata": {
        "id": "5LE2XaO-4jFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=split_text_using_name(['one.txt','four.txt'],['a','b'],no_split=200,num_word=100)\n",
        "df"
      ],
      "metadata": {
        "id": "o6UfGLaCx3mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split_text_using ntlk"
      ],
      "metadata": {
        "id": "BtELjGcD5xME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_using_ntlk(name_books,label_book,no_split=200,num_word=100):\n",
        "  final_list_books=[]\n",
        "  final_list_paragraph=[]\n",
        "  final_list_label=[]\n",
        "  for index in range(len(name_books)):\n",
        "\n",
        "  #read book and make it lower \n",
        "     books=nltk.corpus.gutenberg.fileids()\n",
        "     all_list = nltk.corpus.gutenberg.words(name_books)\n",
        "  \n",
        "  #remove the special cases \n",
        "     clean_list1=[]\n",
        "     for i in all_list:\n",
        "        if re.match(\"[a-zA-Z]+\",i):\n",
        "          clean_list1.append(i)\n",
        "     #print(len(all_list))\n",
        "     #print(len(clean_list1))\n",
        "     #print(clean_list1)\n",
        "\n",
        "  #remove stopwords\n",
        "     stopwords = nltk.corpus.stopwords.words('english')\n",
        "     clean_list2=[]\n",
        "     for i in clean_list1:\n",
        "        if i not in stopwords:\n",
        "          clean_list2.append(i)\n",
        "     #print(len(clean_list1))\n",
        "     #print(len(clean_list2))\n",
        "     #print(clean_list2)\n",
        "  \n",
        "  #split data_text to 200 sample and each of it contain 100 words\n",
        "     list=[]\n",
        "     list_label=[]\n",
        "     for i in range(200):\n",
        "       list.append(clean_list2[i*100:i*100+100])\n",
        "       list_label.append(label_book[index])\n",
        "     final_list_books=final_list_books+list  \n",
        "     final_list_label=final_list_label+list_label\n",
        "  #print(list)   \n",
        "#prepare paragraph from list\n",
        "     paragraph=\" \"\n",
        "     paragraph_list=[]\n",
        "     for x in list:\n",
        "         paragraph=paragraph.join(x) \n",
        "         paragraph_list.append(paragraph)\n",
        "         paragraph=\" \"\n",
        "     final_list_paragraph =final_list_paragraph + paragraph_list \n",
        "#show lists with each label \n",
        "     df=pd.DataFrame({\"part\":final_list_books,\"paragraph\":final_list_paragraph,\"book\":final_list_label})\n",
        "    #  df['paragraph']=paragraph_list\n",
        "    #  df['part']=list\n",
        "    #  df['book']=list_label\n",
        "  return df"
      ],
      "metadata": {
        "id": "A5HhgFgD50KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wiJka47b51SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#call function "
      ],
      "metadata": {
        "id": "v-Bx_qXz6O3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=split_text_using_ntlk(['austen-emma.txt', 'austen-persuasion.txt'],['a','b'],no_split=200,num_word=100)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "u0Xfm3hz6Q7C",
        "outputId": "0dcf721f-53e0-4d97-fe71-52d2d637ba31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  part  \\\n",
              "0    [Emma, Jane, Austen, VOLUME, I, CHAPTER, I, Em...   \n",
              "1    [friend, friend, mutually, attached, Emma, lik...   \n",
              "2    [unexceptionable, character, easy, fortune, su...   \n",
              "3    [arose, affection, could, never, find, fault, ...   \n",
              "4    [evening, must, struggled, Hartfield, Christma...   \n",
              "..                                                 ...   \n",
              "395  [I, say, quite, complete, I, believe, hear, te...   \n",
              "396  [room, There, secrets, families, know, The, ca...   \n",
              "397  [life, She, odd, woman, But, I, never, allow, ...   \n",
              "398  [Mr, Weston, I, dare, say, telling, exactly, m...   \n",
              "399  [To, constantly, living, ill, tempered, person...   \n",
              "\n",
              "                                             paragraph book  \n",
              "0    Emma Jane Austen VOLUME I CHAPTER I Emma Woodh...    a  \n",
              "1    friend friend mutually attached Emma liked hig...    a  \n",
              "2    unexceptionable character easy fortune suitabl...    a  \n",
              "3    arose affection could never find fault How bea...    a  \n",
              "4    evening must struggled Hartfield Christmas bro...    a  \n",
              "..                                                 ...  ...  \n",
              "395  I say quite complete I believe hear telling ot...    b  \n",
              "396  room There secrets families know The case part...    b  \n",
              "397  life She odd woman But I never allow speak ill...    b  \n",
              "398  Mr Weston I dare say telling exactly matter st...    b  \n",
              "399  To constantly living ill tempered person must ...    b  \n",
              "\n",
              "[400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b341f1e-1891-433b-ba63-9f62f4ae56c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>part</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>book</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Emma, Jane, Austen, VOLUME, I, CHAPTER, I, Em...</td>\n",
              "      <td>Emma Jane Austen VOLUME I CHAPTER I Emma Woodh...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[friend, friend, mutually, attached, Emma, lik...</td>\n",
              "      <td>friend friend mutually attached Emma liked hig...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[unexceptionable, character, easy, fortune, su...</td>\n",
              "      <td>unexceptionable character easy fortune suitabl...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[arose, affection, could, never, find, fault, ...</td>\n",
              "      <td>arose affection could never find fault How bea...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[evening, must, struggled, Hartfield, Christma...</td>\n",
              "      <td>evening must struggled Hartfield Christmas bro...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>[I, say, quite, complete, I, believe, hear, te...</td>\n",
              "      <td>I say quite complete I believe hear telling ot...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>[room, There, secrets, families, know, The, ca...</td>\n",
              "      <td>room There secrets families know The case part...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>[life, She, odd, woman, But, I, never, allow, ...</td>\n",
              "      <td>life She odd woman But I never allow speak ill...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>[Mr, Weston, I, dare, say, telling, exactly, m...</td>\n",
              "      <td>Mr Weston I dare say telling exactly matter st...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>[To, constantly, living, ill, tempered, person...</td>\n",
              "      <td>To constantly living ill tempered person must ...</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b341f1e-1891-433b-ba63-9f62f4ae56c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b341f1e-1891-433b-ba63-9f62f4ae56c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b341f1e-1891-433b-ba63-9f62f4ae56c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}